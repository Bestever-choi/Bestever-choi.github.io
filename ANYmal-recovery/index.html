<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<!-- template from Deepak Pathak https://people.eecs.berkeley.edu/~pathak/ -->
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-weight:300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }

  #authors td {
    padding-bottom:5px;
    padding-top:30px;
  }
</style>

<script type="text/javascript" src="resources/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link rel="icon" type="image/png" href="resources/seal_icon.png">
  <title>Towards Practical Multi-object Manipulation using Relational Reinforcement Learning</title>
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="canonical" href="https://richardrl.github.io/relational-rl/" />
  <meta name="referrer" content="no-referrer-when-downgrade" />

  <meta property="og:site_name" content="Relational Reinforcement Learning" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="Towards Practical Multi-object Manipulation using Relational Reinforcement Learning" />
  <meta property="og:description" content="Li, Jabri, Darrell, Agrawal. Towards Practical Multi-object Manipulation using Relational Reinforcement Learning. 2019." />
  <meta property="og:url" content="https://richardrl.github.io/relational-rl/" />
  <meta property="og:image" content="https://pathak22.github.io/modular-assemblies/resources/generalization.png" />
  <meta property="og:video" content="https://www.youtube.com/embed/rW1HTX0VA10" />

  <meta property="article:publisher" content="https://github.com/richardrl/richardrl.github.io/" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Towards Practical Multi-object Manipulation using Relational Reinforcement Learning" />
  <meta name="twitter:description" content="Li, Jabri, Darrell, Agrawal. Towards Practical Multi-object Manipulation using Relational Reinforcement Learning. 2019." />
  <meta name="twitter:url" content="https://richardrl.github.io/relational-rl/" />
  <meta name="twitter:image" content="https://richardrl.github.io/relational-rl/resources/teaser.jpg" />
  <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Richard Li" />
  <meta name="twitter:label2" content="Filed under" />
  <meta name="twitter:data2" content="" />
  <meta name="twitter:site" content="@richardli" />
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

  <script src="https://www.youtube.com/iframe_api"></script>
  <meta name="twitter:card" content="player" />
  <meta name="twitter:image" content="https://richardrl.github.io/relational-rl/resources/teaser.jpg" />
  <meta name="twitter:player" content="https://www.youtube.com/embed/rW1HTX0VA10" />
  <meta name="twitter:player:width" content="640" />
  <meta name="twitter:player:height" content="360" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-89486716-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-89486716-2');
</script>
<!-- 
<script>
var player, seconds = 0;
function onYouTubeIframeAPIReady() {
    console.log("player");
    player = new YT.Player('yt-embed', {
        events: {
          'onReady': onPlayerReady
        }
      });
}

function onPlayerReady(event) {
    event.target.playVideo();
}


function seek(sec){
    if(player){
        seconds += sec;
        player.seekTo(seconds, true);
    }
}</script>
 -->
</head>

<body>
      <br>
      <center><span style="font-size:44px;font-weight:bold;">Recovery controller for ANYmal on various terrains</span></center><br/>
      <table align=center width=600px>
      <tr>
        <td align=center width=150px>
        <center><span style="font-size:22px"><a href="https://wenlong.page/" target="_blank">Kyoungyeon Choi</a></span></center></td>
        <td align=center width=150px>
        <center><span style="font-size:22px"><a href="https://ajabri.github.io/" target="_blank">Allan Jabri</a></span></center></td>
      <tr/>
      <tr>
        <td align=center width=200px>
        <center><span style="font-size:20px">ETH Zurich, SNU</span></center></td>
        <td align=center width=200px>
        <center><span style="font-size:20px">UC Berkeley</span></center></td>
      <tr/>
      </table>


      <table align=center width=700px>
          <tr>
            <td align=center width=200px><center><span style="font-size:22px"><a href="data/FinalReport.pdf">[Report]</a></span></center></td>
            <td align=center width=200px><center><span style="font-size:22px"><a href='data/RSL Presentation Kyoungyeon_Final.pdf'>[Presentation]</a></span></center></td>
            <td align=center width=200px><center><span style="font-size:22px"><a href="https://youtu.be/yt3woILwwhY" target="_blank">[Video]</a></span></center></td>
          <tr/>
      </table><br/>

<!--       <br>
 -->
      <div style="width:800px; margin:0 auto; text-align=center">
      <br />
      Section Timestamps
      Legged robots have promising capabilities of traversing and performing tasks in challenging environments. However, unexpected disturbances can easily lead the robot to fall in such harsh environments. Therefore, it is essential to recover from a fall in various terrains and stabilize itself. There are existing model-based control methods for recovery, but they are based on analytical models and often require predefined contact points that are difficult to optimize. Even on simple flat terrain environments, it is almost impossible to model all the contact sequences and the interactions with the ground. To deal with the complexity of the task, we use modelfree Deep Reinforcement Learning to obtain a robust recovery controller on various terrains. We trained the policy in simulated environments and transferred it to real systems. 
      </div>
      <br><hr>

      <center><h1>ANYmal recovery on sloped terrains</h1></center>
      <div style="width:800px; margin:0 auto; text-align=center">
      The contributions of this project can be divided into 4 parts. 1) Design of a recovery controller on sloped terrain. We train the recovery policy using PPO(Proximal Policy Optimization) on sloped terrain with randomized properties(slope, friction coefficient). 2) Terrain normal vector estimation. For stable behaviors, we find that terrain normal observation is crucial during recovery on sloped terrain. Therefore, a terrain normal estimator is trained using deep neural network. 3) Design of a standing up controller on sloped terrain. After recovery, the robot has to stand up to walk and perform various tasks. With different reward function from the recovery controller, we train a standing up policy. 4) Finite state machine. Finite state machine that enables hybrid control of the two previous policies(recovery, standing up) is designed by transition rules based on state errors. The policy is tested on the quadrupedal robot ANYmal in both simulated and physical environments.
      </div><br/>
      <table align=center width=1000px>
        <p style="margin-top:4px;"></p>
        <tr><td width=1200px>
          <center><a href="data/merge.gif"><img src = "data/merge.gif" height="150px"></img></a><br></center>
        </td></tr>
      </table>

            <br/><hr>

      <center><h1>Emergent Behaviors</h1></center>
      <div style="width:940; height:280; margin:0 auto; text-align=center">

              1. <video width="280" height="280" controls>
  <source src="resources/videos/singulation.mp4" type="video/mp4">
Your browser does not support the video tag.
</video> &nbsp;

      2. <video width="280" height="280" controls>
  <source src="resources/videos/pushing.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>

              3. <video width="280" height="280" controls>
  <source src="resources/videos/pick2place2.mp4" type="video/mp4">
Your browser does not support the video tag.
</video> &nbsp;

            </div>

      <div style="width:800px; margin:0 auto; text-align=center">
        <ol>
  <li> <b>Singulation:</b> (0:02) In order to not knock over the tower, the agent singulates the final black block before picking and placing it. 
  </li>
  
  <li><b>Pushing while grasping:</b> (0:03) The agent performs a rolling/pushing behavior on the green block while grasping the blue block.
  </li>
  
  <li><b>Pick 2, place 2:</b> (0:03) The agent collects the blue and yellow blocks in hand before placing each one by one.
  </li>
</ol>
      </div>


      <br/><hr>

      <center><h1>Failure Modes</h1></center>
      <div style="width:620; height:580px; margin:0 auto; text-align=center">

              1. <video width="280" height="280" controls>
  <source src="resources/failure_videos/stack6->stack7/Oscillation/openaigym.video.0.8643.video000079.mp4" type="video/mp4">
Your browser does not support the video tag.
</video> &nbsp;

      2. <video width="280" height="280" controls>
  <source src="resources/failure_videos/stack6->stack7/No Time to Recover/openaigym.video.0.8643.video000042.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>

              3. <video width="280" height="280" controls>
  <source src="resources/failure_videos/stack6->stack6/Blocks Fall Off - Before Stacked/openaigym.video.0.2340.video000043.mp4" type="video/mp4">
Your browser does not support the video tag.
</video> &nbsp;

      4. <video width="280" height="280" controls>
  <source src="resources/failure_videos/stack6->stack6/Blocks Fall Off - After Stacked/openaigym.video.0.2340.video000064.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
            </div>


      <div style="width:800px; margin:0 auto; text-align=center">
        <ol>
  <li> <b>Oscillation:</b> The agent oscillates its end-effector without progressing towards the goal. 
    Often, this happens when the target block is very close to the base of the tower. In this scenario, 
    picking up the block risks toppling the tower. We hypothesize that in order to reduce this risk, the agent 
    simply oscillates its end-effector. 
  </li>
  
  <li><b>Insufficient recovery time:</b> After 6 blocks have been stacked into a tower, the tower topples. 
    The agent restarts stacking but is unable to stack all the blocks within the maximum time length of the episode. 
  </li>
  
  <li><b>Blocks fall off during stacking:</b> While stacking a tower of 6 blocks, the agent knocks one or more blocks off the table. 
    Because the blocks are no longer on the table, the agent does not succeed. 
  </li>
  
   <li><b>Blocks fall off after stacking:</b> 
     The agent succeeds in stacking a tower of 6 blocks, but the tower topples and block(s) fall off the table.  
   </li>
</ol>
      </div>
    <br/><hr>


<!--     <table align=center width=800px>
      <tr><td width=800px><left> -->
      <div style="width:800px; margin:0 auto; text-align: left">
      <center><h1>Acknowledgements</h1></center>
      We acknowledge support from US Department of Defense, DARPA's Machine Common Sense Grant and the BAIR and BDD industrial consortia.
      We thank Amazon Web Services (AWS) for their generous support in the form of cloud credits.  
      We'd like to thank Vitchyr Pong, Kristian Hartikainen, Ashvin Nair and other members of the BAIR lab and the Improbable AI lab 
      for helpful discussions during this project. <a href="https://people.eecs.berkeley.edu/~pathak/">Template credit</a>. 
<!--       </left></td></tr>
    </table> -->
  <br><br>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>
</html>
